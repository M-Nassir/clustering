{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2dbad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ---------------------------- Imports and Setup ----------------------------\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import random\n",
    "import cProfile\n",
    "import pstats\n",
    "import pickle\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "# Project Root Resolution and add to sys.path\n",
    "CURRENT_DIR = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd()\n",
    "ROOT_PATH = CURRENT_DIR.parent\n",
    "sys.path.insert(0, str(ROOT_PATH))  \n",
    "ROOT_PATH\n",
    "\n",
    "# Internal Module Imports \n",
    "from evaluation.evaluation_configs import dataset_dict, clustering_configs, clustering_flags, selected_metrics, skip_clustering\n",
    "from evaluation.clustering_methods import run_metrics_time_clusterings\n",
    "from utilities.plotting import plot_clusters, plot_enabled_clusterings, plot_confusion_matrices_for_clustering\n",
    "from utilities.cluster_utilities import (\n",
    "    metrics_to_dataframe, average_metrics_dataframe, create_metric_tables_and_save_tex,\n",
    "    median_metrics_dataframe\n",
    ")\n",
    "from utilities.generate_load_data import load_dataset\n",
    "# Dataset Configuration, Loading and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3baea8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# -------------------------- Experiment Configuration ------------------------\n",
    "class Config:\n",
    "    \"\"\"Centralised configuration settings.\"\"\"\n",
    "    PROFILE_CODE = False # Enable to profile code execution time\n",
    "    IS_TESTING = False   # for producing more verbose output during development\n",
    "    PLOT_FIGURES = False # Enable to plot figures for each dataset\n",
    "    SAVE_RESULTS = False  # Save latex tables\n",
    "    SAVE_PLOTS = False   # Save plots to disk\n",
    "    RESULTS_FOLDER = Path(\"results\") # Folder to save results\n",
    "    PLOT_SAVE_PATH = Path.home() / \"Google Drive/docs/A_computational_theory_of_clustering/figures\"\n",
    "    TABLE_SAVE_PATH = Path.home() / \"Google Drive/docs/A_computational_theory_of_clustering/tables\"\n",
    "    RANDOM_SEED = random.randint(0, 10_000)\n",
    "\n",
    "def setup_logging(is_testing: bool) -> logging.Logger:\n",
    "    \"\"\"Initialise logger with verbosity based on mode.\"\"\"\n",
    "    logging.basicConfig(\n",
    "        level=logging.DEBUG if is_testing else logging.INFO,\n",
    "        format=\"%(levelname)s: %(message)s\",\n",
    "        handlers=[logging.StreamHandler()]\n",
    "    )\n",
    "    logging.getLogger(\"matplotlib.font_manager\").setLevel(logging.WARNING)\n",
    "    return logging.getLogger(\"clustering\")\n",
    "\n",
    "# Initialise logger\n",
    "logger = setup_logging(Config.IS_TESTING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faef911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: Loaded dataset '1d_gauss' with parameters:\n",
      "  random_seed       = 5317\n",
      "  k                 = 3\n",
      "  percent_labelled  = 0.002\n",
      "  standardise       = False\n",
      "  Number of seeds   = 33\n",
      "  Number of examples= 17528\n",
      "  Number of features= 1\n",
      "INFO: ******* Preparing to apply clustering methods for dataset 1d_gauss *******\n",
      "INFO: \n",
      "--> Running clustering method: KMeans (Repeat 1/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: KMeans (Repeat 2/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: KMeans (Repeat 3/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: MeanShift (Repeat 1/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: MeanShift (Repeat 2/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: MeanShift (Repeat 3/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: DBSCAN (Repeat 1/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: DBSCAN (Repeat 2/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: DBSCAN (Repeat 3/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: HDBSCAN (Repeat 1/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "/Users/nassirmohammad/anaconda3/envs/conda_arm1/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/nassirmohammad/anaconda3/envs/conda_arm1/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "INFO: \n",
      "--> Running clustering method: HDBSCAN (Repeat 2/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "/Users/nassirmohammad/anaconda3/envs/conda_arm1/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/nassirmohammad/anaconda3/envs/conda_arm1/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "INFO: \n",
      "--> Running clustering method: HDBSCAN (Repeat 3/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "/Users/nassirmohammad/anaconda3/envs/conda_arm1/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/nassirmohammad/anaconda3/envs/conda_arm1/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "INFO: \n",
      "--> Running clustering method: Agglomerative (Repeat 1/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: Agglomerative (Repeat 2/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: Agglomerative (Repeat 3/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: GMM (Repeat 1/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: GMM (Repeat 2/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: GMM (Repeat 3/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: ConstrainedKMeans (Repeat 1/2)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: ConstrainedKMeans (Repeat 2/2)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: COPKMeans (Repeat 1/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: COPKMeans (Repeat 2/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: COPKMeans (Repeat 3/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: SeededKMeans (Repeat 1/2)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: SeededKMeans (Repeat 2/2)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: novel_method (Repeat 1/2)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: novel_method (Repeat 2/2)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n",
      "INFO: \n",
      "--> Running clustering method: DEC (Repeat 1/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: embedding_size is larger than the dimensionality of the input dataset. embedding_size: 10 / input dimensionality: 1\n",
      "Neural network is not fitted yet, will be pretrained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AE training: 100%|██████████| 10/10 [00:11<00:00,  1.16s/it, Training Loss=0.0313]\n",
      "DEC training: 100%|██████████| 10/10 [00:06<00:00,  1.58it/s, Loss=0.599]\n",
      "INFO: \n",
      "--> Running clustering method: DEC (Repeat 2/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: embedding_size is larger than the dimensionality of the input dataset. embedding_size: 10 / input dimensionality: 1\n",
      "Neural network is not fitted yet, will be pretrained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AE training: 100%|██████████| 10/10 [00:12<00:00,  1.27s/it, Training Loss=0.047]\n",
      "DEC training: 100%|██████████| 10/10 [00:06<00:00,  1.48it/s, Loss=0.605]\n",
      "INFO: \n",
      "--> Running clustering method: DEC (Repeat 3/3)\n",
      "INFO: Number of unlabelled examples: 17495\n",
      "INFO: Number of labelled examples: 33\n",
      "INFO: Percentage of labelled data: 0.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: embedding_size is larger than the dimensionality of the input dataset. embedding_size: 10 / input dimensionality: 1\n",
      "Neural network is not fitted yet, will be pretrained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AE training: 100%|██████████| 10/10 [00:13<00:00,  1.33s/it, Training Loss=0.0235]\n",
      "DEC training: 100%|██████████| 10/10 [00:07<00:00,  1.42it/s, Loss=0.605]\n",
      "INFO: ******* Completed running clustering and metrics for dataset 1d_gauss for all methods *******\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: Loaded dataset '2d_gauss' with parameters:\n",
      "  random_seed       = 6772\n",
      "  k                 = 8\n",
      "  percent_labelled  = 0.01\n",
      "  standardise       = False\n",
      "  Number of seeds   = 100\n",
      "  Number of examples= 10300\n",
      "  Number of features= 2\n",
      "INFO: ******* Preparing to apply clustering methods for dataset 2d_gauss *******\n",
      "INFO: \n",
      "--> Running clustering method: KMeans (Repeat 1/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: KMeans (Repeat 2/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: KMeans (Repeat 3/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: MeanShift (Repeat 1/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: MeanShift (Repeat 2/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: MeanShift (Repeat 3/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: DBSCAN (Repeat 1/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: DBSCAN (Repeat 2/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: DBSCAN (Repeat 3/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: HDBSCAN (Repeat 1/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "/Users/nassirmohammad/anaconda3/envs/conda_arm1/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/nassirmohammad/anaconda3/envs/conda_arm1/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "INFO: \n",
      "--> Running clustering method: HDBSCAN (Repeat 2/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "/Users/nassirmohammad/anaconda3/envs/conda_arm1/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/nassirmohammad/anaconda3/envs/conda_arm1/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "INFO: \n",
      "--> Running clustering method: HDBSCAN (Repeat 3/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "/Users/nassirmohammad/anaconda3/envs/conda_arm1/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/nassirmohammad/anaconda3/envs/conda_arm1/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "INFO: \n",
      "--> Running clustering method: Agglomerative (Repeat 1/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: Agglomerative (Repeat 2/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: Agglomerative (Repeat 3/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: GMM (Repeat 1/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: GMM (Repeat 2/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: GMM (Repeat 3/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: ConstrainedKMeans (Repeat 1/2)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: ConstrainedKMeans (Repeat 2/2)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: COPKMeans (Repeat 1/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: COPKMeans (Repeat 2/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: COPKMeans (Repeat 3/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: SeededKMeans (Repeat 1/2)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: SeededKMeans (Repeat 2/2)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: novel_method (Repeat 1/2)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: novel_method (Repeat 2/2)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n",
      "INFO: \n",
      "--> Running clustering method: DEC (Repeat 1/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: embedding_size is larger than the dimensionality of the input dataset. embedding_size: 10 / input dimensionality: 2\n",
      "Neural network is not fitted yet, will be pretrained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AE training: 100%|██████████| 10/10 [00:06<00:00,  1.43it/s, Training Loss=0.0418]\n",
      "DEC training: 100%|██████████| 10/10 [00:04<00:00,  2.40it/s, Loss=8.95]\n",
      "INFO: \n",
      "--> Running clustering method: DEC (Repeat 2/3)\n",
      "INFO: Number of labelled examples: 100\n",
      "INFO: Number of unlabelled examples: 9900\n",
      "INFO: Percentage of labelled data: 1.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: embedding_size is larger than the dimensionality of the input dataset. embedding_size: 10 / input dimensionality: 2\n",
      "Neural network is not fitted yet, will be pretrained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AE training:  70%|███████   | 7/10 [00:05<00:02,  1.29it/s, Training Loss=2.17]  "
     ]
    }
   ],
   "source": [
    "# -------------------------- Run Experiment -----------------------------------\n",
    "\n",
    "# Set this to a specific dataset index to run only one dataset\n",
    "SINGLE_DATASET_INDEX = None\n",
    "dataset_indices = [SINGLE_DATASET_INDEX] if SINGLE_DATASET_INDEX is not None else list(dataset_dict.keys())\n",
    "\n",
    "# holder for all metrics across datasets\n",
    "all_metrics = {}\n",
    "\n",
    "for dataset_index in dataset_indices:\n",
    "    dataset_cfg = dataset_dict[dataset_index]\n",
    "\n",
    "    # Resolve dataset parameters with fallbacks; default get is None\n",
    "    dataset_name = dataset_cfg[\"name\"]\n",
    "    random_seed = dataset_cfg[\"random_seed\"] if dataset_cfg.get(\"random_seed\") is not None else Config.RANDOM_SEED\n",
    "    plot_figures_dataset_specific = dataset_cfg.get(\"plot_figure\", Config.PLOT_FIGURES)\n",
    "    k = dataset_cfg.get(\"k\")\n",
    "    percent_labelled = dataset_cfg.get(\"percent_labelled\")\n",
    "    standardise = dataset_cfg.get(\"standardise\", False)\n",
    "\n",
    "    # load the dataset for plotting purposes and obtaining dataset characteristics\n",
    "    df, num_clusters, plot_title, feature_columns = load_dataset(\n",
    "        dataset_name, random_seed, k, percent_labelled, standardise,\n",
    "    )\n",
    "\n",
    "    # Save for later use\n",
    "    number_of_examples = df.shape[0]\n",
    "    number_of_seeds = (df['y_live'] != -1).sum()\n",
    "    number_of_features = len(feature_columns)\n",
    "\n",
    "    logger.info(\n",
    "        f\"Loaded dataset '{dataset_name}' with parameters:\\n\"\n",
    "        f\"  random_seed       = {random_seed}\\n\"\n",
    "        f\"  k                 = {k}\\n\"\n",
    "        f\"  percent_labelled  = {percent_labelled}\\n\"\n",
    "        f\"  standardise       = {standardise}\\n\"\n",
    "        f\"  Number of seeds   = {number_of_seeds}\\n\"\n",
    "        f\"  Number of examples= {number_of_examples}\\n\"\n",
    "        f\"  Number of features= {number_of_features}\"\n",
    "    )\n",
    "\n",
    "    logger.debug(\"Class distribution (y_live):\\n%s\", df['y_live'].value_counts())\n",
    "\n",
    "    #  -------------------- Plot Dataset and Seeds Separately --------------------\n",
    "\n",
    "    if Config.PLOT_FIGURES:\n",
    "        logger.info(\"Plotting dataset: %s\", dataset_name)\n",
    "\n",
    "        # Plot with true labels\n",
    "        fig1 = plot_clusters(\n",
    "            df,\n",
    "            feature_columns,\n",
    "            label_column='y_true',\n",
    "            x_axis_label='',\n",
    "            y_axis_label='Count',\n",
    "            legend_label='Cluster Labels',\n",
    "            title=f\"{dataset_name} (Ground Truth)\",\n",
    "            show_seeds_only=False,\n",
    "        )\n",
    "\n",
    "        # Plot with seed labels only\n",
    "        fig2 = plot_clusters(\n",
    "            df,\n",
    "            feature_columns,\n",
    "            label_column='y_live',\n",
    "            title=f\"{dataset_name} (Seed Labels Only)\",\n",
    "            show_seeds_only=True,\n",
    "        )\n",
    "\n",
    "        if Config.SAVE_PLOTS:\n",
    "            Config.PLOT_SAVE_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            fig1_path = Config.PLOT_SAVE_PATH / f\"{dataset_name}_ytrue.png\"\n",
    "            fig2_path = Config.PLOT_SAVE_PATH / f\"{dataset_name}_ylive_seeds_only.png\"\n",
    "\n",
    "            fig1.savefig(fig1_path, dpi=300, bbox_inches='tight')\n",
    "            fig2.savefig(fig2_path, dpi=300, bbox_inches='tight')\n",
    "\n",
    "            logger.info(\"Saved plots to:\\n- %s\\n- %s\", fig1_path, fig2_path)\n",
    "\n",
    "    # -------------------- # Execute clustering algorithms based on the provided configurations and flags --------------------\n",
    "    logger.info(\"******* Preparing to apply clustering methods for dataset %s *******\" % dataset_name)\n",
    "\n",
    "    if Config.PROFILE_CODE:\n",
    "        pr = cProfile.Profile()\n",
    "        pr.enable()\n",
    "        \n",
    "    metrics_df, df_one_result = run_metrics_time_clusterings(\n",
    "        dataset_name = dataset_name,\n",
    "        random_seed = Config.RANDOM_SEED,\n",
    "        k = k,\n",
    "        percent_labelled = percent_labelled,\n",
    "        standardise = standardise,\n",
    "        clustering_configs = clustering_configs,\n",
    "        clustering_flags = clustering_flags,\n",
    "        skip_clusterings = skip_clustering,\n",
    "        num_repeats=2,\n",
    "        load_dataset=load_dataset,\n",
    "        selected_metrics=selected_metrics,\n",
    "        num_examples = number_of_examples,\n",
    "    )\n",
    "    \n",
    "    all_metrics[dataset_name] = metrics_df\n",
    "\n",
    "    if Config.PROFILE_CODE:\n",
    "        pr.disable()\n",
    "\n",
    "        # Create a stream to hold profiling stats\n",
    "        s = io.StringIO()\n",
    "        sortby = 'cumtime'  # Sort by cumulative time to see bottlenecks\n",
    "\n",
    "        ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "        ps.print_stats(50)  # Show top 50 lines\n",
    "        print(s.getvalue())\n",
    "\n",
    "    logger.info(\"******* Completed running clustering and metrics for dataset %s for all methods *******\" % dataset_name)\n",
    "\n",
    "    # Plot results of enabled clustering algorithms if plotting is enabled\n",
    "    if Config.IS_TESTING:\n",
    "        if plot_figures_dataset_specific: # this tells us if in config file we want to plot for this dataset\n",
    "            plot_enabled_clusterings(\n",
    "                df,\n",
    "                clustering_flags,\n",
    "                feature_columns,\n",
    "                plot_save_path=Config.PLOT_SAVE_PATH,\n",
    "                dataset_name=dataset_name,\n",
    "                save_plots=Config.SAVE_PLOTS,\n",
    "            )\n",
    "\n",
    "    # ---------------------------- Plot Confusion Matrices ------------------------\n",
    "    # Plot confusion matrices for all enabled clustering methods\n",
    "    if Config.IS_TESTING:\n",
    "        plot_confusion_matrices_for_clustering(\n",
    "            df, \n",
    "            true_label_col='y_true', \n",
    "            clustering_flags=clustering_flags\n",
    "        )\n",
    "\n",
    "    # -- run only for MNIST and 6NewsgroupsUMAP10\n",
    "\n",
    "    if dataset_name == '6NewsgroupsUMAP10':\n",
    "\n",
    "        # Define file path\n",
    "        project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "        csv_file_path = os.path.join(project_root, \"data\", \"processed\", \"6NewsgroupsUMAP2_embeddings.csv\")\n",
    "\n",
    "        # Load embeddings\n",
    "        df_vis = pd.read_csv(csv_file_path)\n",
    "\n",
    "        def format_email_body(text, words_per_line=10):\n",
    "            words = str(text).split()\n",
    "            lines = [' '.join(words[i:i+words_per_line]) for i in range(0, len(words), words_per_line)]\n",
    "            return '<br>'.join(lines)\n",
    "\n",
    "        # Create a formatted email body column with line breaks every 10 words for hover display\n",
    "        df_vis['email_body_formatted'] = df_vis['email_body'].apply(format_email_body)\n",
    "\n",
    "        # Assign clustering results and labels from df_one_result dict\n",
    "        for col in ['KMeans', 'novel_method']:\n",
    "            if col in df_one_result:\n",
    "                # Assign y_true and y_live only once if not present\n",
    "                if 'y_true' not in df_vis:\n",
    "                    df_vis['y_true'] = df_one_result[col]['y_true']\n",
    "                if 'y_live' not in df_vis:\n",
    "                    df_vis['y_live'] = df_one_result[col]['y_live']\n",
    "\n",
    "                # Assign clustering results for this method\n",
    "                df_vis[col] = df_one_result[col][col]\n",
    "            else:\n",
    "                raise KeyError(f\"Column '{col}' not found in df_one_result\")\n",
    "\n",
    "        # Define a custom, high-contrast colour palette (20 colours)\n",
    "        custom_colors = [\n",
    "            '#1f77b4', '#ff7f0e', '#2ca02c', '#9467bd', '#8c564b',\n",
    "            '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#aec7e8',\n",
    "            '#ffbb78', '#98df8a', '#c5b0d5', '#c49c94', '#f7b6d2',\n",
    "            '#c7c7c7', '#dbdb8d', '#9edae5', '#393b79', '#637939'\n",
    "        ]\n",
    "\n",
    "        # Build global color map across all label columns for consistency\n",
    "        label_columns = ['y_true', 'y_live', 'KMeans', 'novel_method']\n",
    "        all_labels = set()\n",
    "\n",
    "        for col in label_columns:\n",
    "            if col in df_vis:\n",
    "                all_labels.update(df_vis[col].astype(str).unique())\n",
    "\n",
    "        # Make sure '-1' (anomalies) is first and red\n",
    "        all_labels.discard('-1')\n",
    "        ordered_labels = ['-1'] + sorted(all_labels, key=int)\n",
    "\n",
    "        global_color_map = {\n",
    "            lbl: ('rgb(255,0,0)' if lbl == '-1' else custom_colors[i % len(custom_colors)])\n",
    "            for i, lbl in enumerate(ordered_labels)\n",
    "        }\n",
    "\n",
    "        df_vis['index'] = df_vis.index.astype(str)\n",
    "\n",
    "        for label_col in label_columns:\n",
    "            if label_col not in df_vis:\n",
    "                continue  # skip if column missing\n",
    "\n",
    "            df_vis[label_col] = df_vis[label_col].astype(str)\n",
    "\n",
    "            # Only keep labels present in this column, preserving order from global\n",
    "            ordered_categories = [lbl for lbl in ordered_labels if lbl in df_vis[label_col].values]\n",
    "\n",
    "            # Use subset of global color map for this column\n",
    "            color_map = {lbl: global_color_map[lbl] for lbl in ordered_categories}\n",
    "\n",
    "            # Define hover columns, excluding current label_col\n",
    "            hover_cols = [\n",
    "                col for col in ['index', 'y_true', 'y_live', 'KMeans', 'novel_method', 'category', 'top_keywords', 'email_body_formatted']\n",
    "                if col != label_col and col in df_vis.columns\n",
    "            ]\n",
    "\n",
    "            fig = px.scatter(\n",
    "                df_vis,\n",
    "                x='UMAP_1',\n",
    "                y='UMAP_2',\n",
    "                color=label_col,\n",
    "                color_discrete_map=color_map,\n",
    "                category_orders={label_col: ordered_categories},\n",
    "                hover_name=None,\n",
    "                hover_data=hover_cols,\n",
    "                title=f'UMAP projection colored by {label_col}',\n",
    "                width=1400,\n",
    "                height=900,\n",
    "            )\n",
    "\n",
    "            # Add white edges to markers\n",
    "            for trace in fig.data:\n",
    "                trace.marker.line.color = 'white'\n",
    "                trace.marker.line.width = 1.5\n",
    "\n",
    "            fig.update_layout(\n",
    "                legend_title_text=label_col,\n",
    "                plot_bgcolor='white',\n",
    "                paper_bgcolor='white',\n",
    "                xaxis=dict(\n",
    "                    title='', showgrid=False, showline=True,\n",
    "                    linecolor='black', linewidth=1,\n",
    "                    zeroline=False, ticks='outside'\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    title='', showgrid=False, showline=True,\n",
    "                    linecolor='black', linewidth=1,\n",
    "                    zeroline=False, scaleanchor=\"x\",\n",
    "                    scaleratio=1, ticks='outside'\n",
    "                )\n",
    "            )\n",
    "\n",
    "            fig.show()\n",
    "\n",
    "\n",
    "    # -- run only for MNIST\n",
    "\n",
    "    if dataset_name == 'MNIST_UMAP10':\n",
    "        logging.debug(\"Running UMAP visualization for MNIST dataset...\")\n",
    "\n",
    "        # Define save directory\n",
    "        os.makedirs(Config.PLOT_SAVE_PATH, exist_ok=True)\n",
    "\n",
    "        # Define file path\n",
    "        project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "        csv_file_path = os.path.join(project_root, \"data\", \"processed\", \"MNIST_UMAP2_with_images.csv\")\n",
    "\n",
    "        # Load embeddings\n",
    "        df_vis = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Assign clustering results and labels from df_one_result dict\n",
    "        for col in ['KMeans', 'novel_method']:\n",
    "            if col in df_one_result:\n",
    "                # Assign y_true and y_live only once if not present\n",
    "                if 'y_true' not in df_vis:\n",
    "                    df_vis['y_true'] = df_one_result[col]['y_true']\n",
    "                if 'y_live' not in df_vis:\n",
    "                    df_vis['y_live'] = df_one_result[col]['y_live']\n",
    "\n",
    "                # Assign clustering results for this method\n",
    "                df_vis[col] = df_one_result[col][col]\n",
    "            else:\n",
    "                raise KeyError(f\"Column '{col}' not found in df_one_result\")\n",
    "\n",
    "        df_vis['index'] = df_vis.index.astype(str)\n",
    "\n",
    "        # Collect global labels\n",
    "        all_labels = set()\n",
    "        for label_col in ['y_true', 'y_live', 'KMeans', 'novel_method']:\n",
    "            all_labels.update(df_vis[label_col].unique())\n",
    "\n",
    "        all_labels = {str(l) for l in all_labels}\n",
    "        unique_labels = sorted([l for l in all_labels if l != '-1'], key=int)\n",
    "        ordered_categories = ['-1'] + unique_labels if '-1' in all_labels else unique_labels\n",
    "\n",
    "        # Custom colours\n",
    "        custom_colors = [\n",
    "            '#1f77b4', '#ff7f0e', '#2ca02c', '#9467bd', '#8c564b',\n",
    "            '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#aec7e8',\n",
    "            '#ffbb78', '#98df8a', '#c5b0d5', '#c49c94', '#f7b6d2',\n",
    "            '#c7c7c7', '#dbdb8d', '#9edae5', '#393b79', '#637939'\n",
    "        ]\n",
    "\n",
    "        custom_colors = [\n",
    "            'green', 'blue', 'black',\n",
    "            'orange', 'purple', 'brown',\n",
    "            'pink', 'cyan', 'darkblue',\n",
    "            'violet', 'magenta', 'black',\n",
    "        ]\n",
    "\n",
    "        global_color_map = {}\n",
    "        for i, lbl in enumerate(ordered_categories):\n",
    "            global_color_map[lbl] = 'rgb(255,0,0)' if lbl == '-1' else custom_colors[i % len(custom_colors)]\n",
    "\n",
    "        # Create and save plots\n",
    "        for label_col in ['y_true', 'y_live', 'KMeans', 'novel_method']:\n",
    "            df_vis[label_col] = df_vis[label_col].astype(str)\n",
    "\n",
    "            hover_cols = [c for c in ['index', 'y_true', 'y_live', 'KMeans', 'novel_method'] if c != label_col and c in df_vis.columns]\n",
    "\n",
    "            fig = px.scatter(\n",
    "                df_vis,\n",
    "                x='UMAP_1',\n",
    "                y='UMAP_2',\n",
    "                color=label_col,\n",
    "                color_discrete_map=global_color_map,\n",
    "                category_orders={label_col: ordered_categories},\n",
    "                hover_name=None,\n",
    "                hover_data=hover_cols,\n",
    "                title=f'UMAP projection colored by {label_col}',\n",
    "                width=1400,\n",
    "                height=900,\n",
    "            )\n",
    "\n",
    "            # Add white borders\n",
    "            for trace in fig.data:\n",
    "                trace.marker.line.color = 'white'\n",
    "                trace.marker.line.width = 1.5\n",
    "\n",
    "            fig.update_layout(\n",
    "                legend_title_text=label_col,\n",
    "                plot_bgcolor='white',\n",
    "                paper_bgcolor='white',\n",
    "                xaxis=dict(\n",
    "                    title='', showgrid=False, showline=True,\n",
    "                    linecolor='black', linewidth=1,\n",
    "                    zeroline=False, ticks='outside'\n",
    "                ),\n",
    "                yaxis=dict(\n",
    "                    title='', showgrid=False, showline=True,\n",
    "                    linecolor='black', linewidth=1,\n",
    "                    zeroline=False, scaleanchor=\"x\",\n",
    "                    scaleratio=1, ticks='outside'\n",
    "                )\n",
    "            )\n",
    "\n",
    "            fig.show()\n",
    "\n",
    "            # Save to file\n",
    "            save_file = os.path.join(Config.PLOT_SAVE_PATH, f\"mnist_umap_{label_col}.png\")\n",
    "            fig.write_image(save_file, scale=2)  # scale=2 improves resolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd892da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% -------------------- Convert all metrics to a DataFrame for easier analysis --------------------\n",
    "metric_tables = {}\n",
    "\n",
    "if Config.SAVE_RESULTS:\n",
    "    df_metrics = metrics_to_dataframe(all_metrics)\n",
    "    df_metrics[\"value\"] = df_metrics[\"value\"].round(2)\n",
    "\n",
    "    # Use median metrics\n",
    "    df_median_metrics = median_metrics_dataframe(df_metrics)\n",
    "    metric_tables = create_metric_tables_and_save_tex(df_median_metrics, Config.TABLE_SAVE_PATH)\n",
    "\n",
    "# Display styled tables and save raw dataframes\n",
    "for metric, df in metric_tables.items():\n",
    "    # Choose colour map\n",
    "    cmap = \"Reds_r\" if 'runtime (s)' in metric.lower() else \"Greens\"\n",
    "    \n",
    "    # Format values for display\n",
    "    formatter = lambda x: \"--\" if pd.isna(x) else f\"{x:.2f}\"\n",
    "\n",
    "    # Display styled table\n",
    "    styled = (\n",
    "        df.style\n",
    "        .background_gradient(cmap=cmap, axis=1)\n",
    "        .format(formatter)\n",
    "        .set_caption(metric)\n",
    "    )\n",
    "    display(styled)\n",
    "\n",
    "    if Config.SAVE_RESULTS:\n",
    "        # Save each dataframe as CSV\n",
    "        filename = metric.lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\") + \".csv\"\n",
    "        df.to_csv(os.path.join(Config.RESULTS_FOLDER, filename), index=True)\n",
    "\n",
    "if Config.SAVE_RESULTS:\n",
    "    # Save entire metric_tables dictionary\n",
    "    with open(os.path.join(Config.RESULTS_FOLDER, \"metric_tables.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(metric_tables, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_arm1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
