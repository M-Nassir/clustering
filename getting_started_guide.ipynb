{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------- Imports ---------------------------------\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# # Get the current working directory (where the notebook is running from)\n",
    "# notebook_dir = os.getcwd()\n",
    "\n",
    "# # Go up 2 levels to reach the 'clustering' project root\n",
    "# root_path = os.path.abspath(os.path.join(notebook_dir, '../../'))\n",
    "# if root_path not in sys.path:\n",
    "#     sys.path.insert(0, root_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generation utilities\n",
    "from data.synthetic.one_dim_data import generate_clustering_1d_data\n",
    "from data.synthetic.one_dim_data_gauss import generate_clustering_1d_gauss_anomalies\n",
    "from data.synthetic.two_dim_data_gauss import generate_clustering_2d_gauss_data\n",
    "\n",
    "# clustering method \n",
    "from clustering_methods import novel_clustering, seeded_k_means_clustering, kmeans_clustering, dbscan_clustering\n",
    "\n",
    "# # Plotting tools\n",
    "from utilities.plotting import plot_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data or read in data with a tiny amount of labelled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- Data Setup ---------------------------------\n",
    "\n",
    "# Define dataset mode\n",
    "mode = \"1d_gauss\"  # Options: \"1d_simple\", \"1d_gauss\", \"2d_gauss\"\n",
    "k = None  # Number of clusters (used by some algorithms like k-means, we supply ground truth number)\n",
    "\n",
    "# Load selected dataset and plot\n",
    "if mode == \"1d_simple\":\n",
    "    k = 3\n",
    "    df = generate_clustering_1d_data(repeat_const=100, percent_labelled=0.03, random_state=None)\n",
    "\n",
    "elif mode == \"1d_gauss\":\n",
    "    k = 3\n",
    "    df = generate_clustering_1d_gauss_anomalies(random_seed=42,\n",
    "                                               labelled_percent=0.1,\n",
    "                                               cluster_params=[(0, 1), (50, 3), (100, 6)],\n",
    "                                               samples_per_cluster=10000,\n",
    "                                               include_anomaly_cluster=True,\n",
    "                                               )\n",
    "\n",
    "elif mode == \"2d_gauss\":\n",
    "    k=5\n",
    "    df = generate_clustering_2d_gauss_data(n_samples=10000,\n",
    "                                        n_components=k,\n",
    "                                        num_features=2,\n",
    "                                        rand_seed=0,\n",
    "                                        same_density=False,\n",
    "                                        labelled_fraction=0.01,\n",
    "                                        add_anomaly_cluster=True,\n",
    "                                        plot=True,\n",
    "                                        )\n",
    "\n",
    "# Extract feature columns from the DataFrame\n",
    "feature_columns = [col for col in df.columns if col not in {'y_true', 'y_live'}]\n",
    "\n",
    "# assign the dataset name\n",
    "dataset_name = mode\n",
    "\n",
    "plot_clusters(df, feature_columns, label_column='y_true', title=dataset_name + ' (all data with histogram overlay)', show_seeds_only=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(df, feature_columns, label_column='y_live', title=dataset_name + ' (seeds only)', show_seeds_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run novel clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the novel clustering algorithm\n",
    "# ensure dataframe has 'y_live' column of partially labelled data for semi-supervised clustering\n",
    "df_c = df.copy()\n",
    "df_novel = novel_clustering(df_c, feature_columns, seeds='y_live')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_novel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_clusters(df_novel, feature_columns, label_column='novel_method', title=\"Novel Clustering Results: \" + dataset_name, show_seeds_only=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeded k-means method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df.copy()\n",
    "df_seeded_k_means = seeded_k_means_clustering(df_c, feature_columns, target_column='y_true', seeds='y_live', n_clusters=3, random_state=0, remap_labels=False)\n",
    "print(df_seeded_k_means)\n",
    "plot_clusters(df_seeded_k_means, feature_columns, label_column='SeededKMeans', title=\"SeededKMeans Clustering Results: \" + dataset_name, show_seeds_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df.copy()\n",
    "df_k_means = kmeans_clustering(df_c, feature_columns, target_column='y_true', n_clusters=3, random_state=0, remap_labels=False)\n",
    "print(df_k_means)\n",
    "plot_clusters(df_k_means, feature_columns, label_column='KMeans', title=\"KMeans Clustering Results: \" + dataset_name, show_seeds_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN clustering method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from kneed import KneeLocator\n",
    "\n",
    "def estimate_eps(df, feature_columns, k=5, zoom_ymax=2.0, detect_knee=True):\n",
    "    \"\"\"\n",
    "    Estimate a good eps value for DBSCAN using the k-distance method.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing your data.\n",
    "    - feature_columns: list of feature column names (1D or 2D).\n",
    "    - k: number of neighbours (min_samples = k).\n",
    "    - zoom_ymax: max Y limit to zoom into the k-distance plot.\n",
    "    - detect_knee: whether to automatically find the elbow point.\n",
    "\n",
    "    Returns:\n",
    "    - eps: Estimated eps value.\n",
    "    \"\"\"\n",
    "\n",
    "    X = df[feature_columns].values\n",
    "\n",
    "    # Fit NearestNeighbors\n",
    "    neigh = NearestNeighbors(n_neighbors=k)\n",
    "    nbrs = neigh.fit(X)\n",
    "    distances, _ = nbrs.kneighbors(X)\n",
    "\n",
    "    # Sort the k-th distance (k-1 index since indexing starts at 0)\n",
    "    k_distances = np.sort(distances[:, k - 1])\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(k_distances)\n",
    "    plt.ylim(0, zoom_ymax)\n",
    "    plt.title(f'k-distance plot (k={k})')\n",
    "    plt.xlabel('Points sorted by distance')\n",
    "    plt.ylabel(f'{k}th nearest neighbour distance')\n",
    "\n",
    "    eps = None\n",
    "    if detect_knee:\n",
    "        knee_locator = KneeLocator(\n",
    "            range(len(k_distances)),\n",
    "            k_distances,\n",
    "            curve='convex',\n",
    "            direction='increasing'\n",
    "        )\n",
    "        eps = k_distances[knee_locator.knee] if knee_locator.knee is not None else None\n",
    "        if eps:\n",
    "            plt.axhline(y=eps, color='red', linestyle='--', label=f\"Estimated eps = {eps:.4f}\")\n",
    "            plt.legend()\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return eps\n",
    "\n",
    "eps = estimate_eps(df, feature_columns=['X'], k=4, zoom_ymax=1.0, detect_knee=True)\n",
    "print(f\"Estimated eps: {eps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eps selected as according to paper visually to be 0.1\n",
    "# knee locator suggests 1\n",
    "# min_samples = number_of_dimensions + 1 = 4\n",
    "# sensitive to parameters eps and min_samples\n",
    "df_c = df.copy()\n",
    "df_dbscan = dbscan_clustering(df_c, feature_columns, target_column='y_true', eps=0.1, min_samples=4, remap_labels=False)\n",
    "print(df_dbscan)\n",
    "plot_clusters(df_dbscan, feature_columns, label_column='DBSCAN', title=\"DBSCAN Clustering Results: \" + dataset_name, show_seeds_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_arm1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
